# Name: Youssef Shafeek
# Date: 05/27/2025
# File Description: This module defines the insights generation agent. It uses 
# GPT-based LLM to analyze a batch of customer feedback and generate actionable business
# insights. The output is bullet point format that can be included in reports
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
import os

# Load environment variable (OpenAI API key from .env file)
load_dotenv()

# Intitialize the language model with a deterministic output (temperature = 0)
llm = ChatOpenAI(temperature=0, model="gpt-4o-mini")

# Define the prompt template to guide the LLM in generating specific insights
prompt = ChatPromptTemplate.from_template("""
You are an operational strategy assistant for a product enterprise company.

Based on the following customer feedback, generate 3 to 4 clear and actionable insights that the business operations 
or customer service team could act on to enchance product quality and customer satisfaction. 

- Keep the insights concise and business-focused.
- Avoid generalities like "Improve service" â€” be specific about what action should be taken.
- Format the output as a bulleted list. 

Customer Feedback:
{feedback_list}

Insights:
""")

# Creates a runnable LLM chain that combines the model and prompt
insight_chain = prompt | llm

# This function processes a list of customer feedback strings and returns a list 
# of business-focused insights generated by a GPT model.
def generate_insights(feedback_texts: list[str]) -> str:
    # Joins the feedback entries into a bullet style string for better LLM understanding
    joined_feedback = "\n- " + "\n- ".join(feedback_texts)
    # Invoke the LLM with the formatted list
    result = insight_chain.invoke({"feedback_list": joined_feedback})
    # Return only the content portion, removing any whitespace
    return result.content.strip()
